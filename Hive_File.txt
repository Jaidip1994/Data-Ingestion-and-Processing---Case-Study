-- Adding the jar file 
ADD JAR /opt/cloudera/parcels/CDH/lib/hive/lib/hive-hcatalog-core-1.1.0-cdh5.11.2.jar;

-- PARTITION THE DATA  
-- IMPORTANT: BEFORE PARTITIONING ANY TABLE,
SET hive.exec.max.dynamic.partitions=100000;
SET hive.exec.max.dynamic.partitions.pernode=100000;

-- Delete Table if already exists
DROP TABLE new_york_taxi;

-- Create Table 
create external table if not exists new_york_taxi
(
VendorID int,
tpep_pickup_datetime timestamp, 
tpep_dropoff_datetime timestamp,
Passenger_count int,
Trip_distance double,
RateCodeID int, 
Store_and_fwd_flag string, 
PULocationID string, 
DOLocationID string,
Payment_type int,
Fare_amount double, 
Extra double,
MTA_tax double,
Tip_amount double,
Tolls_amount double,
Improvement_surcharge double,
Total_amount double)
ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
location '/common_folder/nyc_taxi_data'
tblproperties("skip.header.line.count"="1");

-- To Check whether the Data was imported properly or not
SELECT * from new_york_taxi limit 5;

-- o/p: of the Query
-- new_york_taxi.vendorid	new_york_taxi.tpep_pickup_datetime	new_york_taxi.tpep_dropoff_datetime	new_york_taxi.passenger_count	new_york_taxi.trip_distance	new_york_taxi.pulocationid	new_york_taxi.dolocationid	new_york_taxi.ratecodeid	new_york_taxi.store_and_fwd_flag	new_york_taxi.payment_type	new_york_taxi.fare_amount	new_york_taxi.extra	new_york_taxi.mta_tax	new_york_taxi.improvement_surcharge	new_york_taxi.tip_amount	new_york_taxi.tolls_amount	new_york_taxi.total_amount
-- 1	01-11-17 00:01:00.0	01-11-17 00:03:00.0	1	0.4	1	N	151	151	2	3.5	    0.5	0.5	0	    0	0.3	4.8
-- 2	01-11-17 00:31:00.0	01-11-17 00:31:00.0	1	0	1	N	193	193	2	2.5	    0.5	0.5	0	    0	0.3	3.8
-- 1	01-11-17 00:25:00.0	01-11-17 00:40:00.0	1	2.9	1	N	50	249	1	12.5	0.5	0.5	2.75	0	0.3	16.55
-- 1	01-11-17 00:17:00.0	01-11-17 00:30:00.0	1	3	1	N	79	230	1	11.5	0.5	0.5	2.55	0	0.3	15.35
-- 1	01-11-17 00:38:00.0	01-11-17 01:01:00.0	1	4.2	1	N	113	33	1	18.5	0.5	0.5	3.95	0	0.3	23.75



-- Part I :Basic Data Quality Checks
-- 1. How many records has each TPEP provider provided? Write a query that summarises the number of records of each provider.
SELECT VendorID , count(*) as no_of_record 
from new_york_taxi
group by VendorID;

-- o/p
--  	| vendorid	| no_of_record
-- 1	| 2	        | 647183
-- 2	| 1	        | 527386
-- So for Creative Mobile Technologies : 527386 ( No of Records ) and for VeriFone Inc. : 647183 (No of Records )


-- 2. The data provided is for months November and December only. Check whether the data is consistent, and if not, 
-- identify the data quality issues. Mention all data quality issues in comments.
-- Lets the Data Distribution based on Month and Year ( As this will help to partition the Data
-- The data is for the two months Nov 2017 and Dec 2017
SELECT 
year(from_unixtime(unix_timestamp( tpep_pickup_datetime))) AS year_in_dat , 
month(from_unixtime(unix_timestamp( tpep_pickup_datetime))) as month_in_dat,
count(*) as Number_of_Records
from new_york_taxi
group by year(from_unixtime(unix_timestamp( tpep_pickup_datetime))),
         month(from_unixtime(unix_timestamp( tpep_pickup_datetime)));

-- o/p: of the Query         
-- year_in_dat	month_in_dat	number_of_records
-- 2003	1	1
-- 2008	12	2
-- 2009	1	1
-- 2017	11	580300
-- 2017	10	6
-- 2017	12	594255
-- 2018	1	4
-- 
-- As we can see Below some Data are of year 2003, 2008, 2009 ( so these are the data which is not relevant for the current use case )
-- But some data are also there of Oct 2017 and Jan 2018, this is like the Trip started around Midnight
-- So lets Analyze some more Data where the Year is 2017 and month is 10 and year is 2018 and the month is 1
-- Idea is get all the record whose pickup is at 31st Oct 2017 and 1st Jan 2018 and Drop off Time is in 31st October 2017 and
-- Drop Off Time > 1st Jan 2018
SELECT
tpep_pickup_datetime ,
tpep_dropoff_datetime
FROM new_york_taxi
WHERE ( year(from_unixtime(unix_timestamp( tpep_pickup_datetime))) == 2017 AND 
        month(from_unixtime(unix_timestamp( tpep_pickup_datetime))) == 10 ) OR
      ( year(from_unixtime(unix_timestamp( tpep_pickup_datetime))) == 2018 AND 
        month(from_unixtime(unix_timestamp( tpep_pickup_datetime))) == 1 ) OR 
      ( year(from_unixtime(unix_timestamp( tpep_dropoff_datetime))) == 2017 AND 
        month(from_unixtime(unix_timestamp( tpep_dropoff_datetime))) == 10 ) OR
      ( year(from_unixtime(unix_timestamp( tpep_dropoff_datetime))) == 2018 AND 
        month(from_unixtime(unix_timestamp( tpep_dropoff_datetime))) == 1  AND day(from_unixtime(unix_timestamp( tpep_dropoff_datetime))) > 1 );    
ORDER BY from_unixtime(unix_timestamp( tpep_pickup_datetime));

-- As we can see below there are around 10 records, out of which for 6 records the pickup time is on 31st October 2017 and 4 records for whom the pickup time is  at 1st Jan 2018
--  	tpep_pickup_datetime	tpep_dropoff_datetime
-- 1	2017-10-31 11:23:00.0	2017-10-31 11:28:00.0
-- 2	2017-10-31 18:33:00.0	2017-10-31 18:38:00.0
-- 3	2017-10-31 18:56:00.0	2017-11-01 18:18:00.0
-- 4	2017-10-31 23:59:00.0	2017-11-01 00:10:00.0
-- 5	2017-10-31 23:59:00.0	2017-11-01 00:06:00.0
-- 6	2017-10-31 23:59:00.0	2017-11-01 00:11:00.0
-- 7	2018-01-01 00:00:00.0	2018-01-01 00:00:00.0
-- 8	2018-01-01 00:00:00.0	2018-01-01 00:15:00.0
-- 9	2018-01-01 00:00:00.0	2018-01-01 00:12:00.0
-- 10	2018-01-01 00:04:00.0	2018-01-01 00:17:00.0
-- So these records are also not valid

-- So lets identify how many records are out of range 
SELECT tpep_pickup_datetime, tpep_dropoff_datetime  
FROM new_york_taxi
WHERE NOT ( tpep_pickup_datetime BETWEEN '2017-11-01 00:00:00.0' AND '2017-12-31 23:59:59.0' AND 
          tpep_dropoff_datetime BETWEEN '2017-11-01 00:00:00.0' AND '2018-01-01 23:59:59.0' )
order by tpep_pickup_datetime, tpep_dropoff_datetime;

-- o/p
--  	tpep_pickup_datetime	tpep_dropoff_datetime
-- 1	2003-01-01 00:58:00.0	2003-01-01 01:28:00.0
-- 2	2008-12-31 10:27:00.0	2008-12-31 10:48:00.0
-- 3	2008-12-31 23:53:00.0	2009-01-01 00:03:00.0
-- 4	2009-01-01 00:13:00.0	2009-01-01 00:32:00.0
-- 5	2017-10-31 11:23:00.0	2017-10-31 11:28:00.0
-- 6	2017-10-31 18:33:00.0	2017-10-31 18:38:00.0
-- 7	2017-10-31 18:56:00.0	2017-11-01 18:18:00.0
-- 8	2017-10-31 23:59:00.0	2017-11-01 00:06:00.0
-- 9	2017-10-31 23:59:00.0	2017-11-01 00:10:00.0
-- 10	2017-10-31 23:59:00.0	2017-11-01 00:11:00.0
-- 11	2017-11-14 13:50:00.0	2019-04-24 19:21:00.0
-- 12	2018-01-01 00:00:00.0	2018-01-01 00:00:00.0
-- 13	2018-01-01 00:00:00.0	2018-01-01 00:12:00.0
-- 14	2018-01-01 00:00:00.0	2018-01-01 00:15:00.0
-- 15	2018-01-01 00:04:00.0	2018-01-01 00:17:00.0
-- Above are the records which are not in range out of that there is a peculiar record, 11th Record of the above output,
-- where the droptime stamp is at 2019

-- Lets see whether the dropofftime is less than pickup time or not
SELECT count(*) as no_of_records 
FROM new_york_taxi
WHERE  tpep_dropoff_datetime < tpep_pickup_datetime;
-- o/p
--  	no_of_records
-- 1	73
-- Number of records are around 73 for which the drop off time is less than pickup time

-- Lets check some more information
SELECT * 
FROM new_york_taxi
WHERE  tpep_dropoff_datetime < tpep_pickup_datetime
LIMIT 5;
-- o/p
--  	new_york_taxi.vendorid	new_york_taxi.tpep_pickup_datetime	new_york_taxi.tpep_dropoff_datetime	new_york_taxi.passenger_count	new_york_taxi.trip_distance	new_york_taxi.ratecodeid	new_york_taxi.store_and_fwd_flag	new_york_taxi.pulocationid	new_york_taxi.dolocationid	new_york_taxi.payment_type	new_york_taxi.fare_amount	new_york_taxi.extra	new_york_taxi.mta_tax	new_york_taxi.tip_amount	new_york_taxi.tolls_amount	new_york_taxi.improvement_surcharge	new_york_taxi.total_amount
-- 1	1	2017-11-05 01:58:00.0	2017-11-05 01:02:00.0	1	0.3	1	N	264	264	1	4	0.5	0.5	1.05	0	0.3	6.35
-- 2	1	2017-11-05 01:58:00.0	2017-11-05 01:10:00.0	1	2.1	1	N	234	48	1	10	0.5	0.5	2	0	0.3	13.3
-- 3	1	2017-11-05 01:27:00.0	2017-11-05 01:09:00.0	2	15.7	1	N	140	14	2	47	0.5	0.5	0	0	0.3	48.3
-- 4	1	2017-11-05 01:58:00.0	2017-11-05 01:14:00.0	1	3.3	1	N	249	142	1	13.5	0.5	0.5	2	0	0.3	16.8
-- 5	1	2017-11-05 01:45:00.0	2017-11-05 01:27:00.0	1	9	1	N	148	61	1	33.5	0.5	0.5	8.7	0	0.3	43.5
-- As we can see for the above records drop off time is less than pick up time
-- Location is Changing
-- Customer has also paid ( as we can see the total amount of paid )
-- So these records looks has some fault

-- Lets check out how many such records are there and for which vendor the most number of error data are present
SELECT vendorid, count(*) no_of_records
FROM new_york_taxi
WHERE NOT ( tpep_pickup_datetime BETWEEN '2017-11-01 00:00:00.0' AND '2017-12-31 23:59:59.0' AND 
          tpep_dropoff_datetime BETWEEN '2017-11-01 00:00:00.0' AND '2018-01-01 23:59:59.0' ) OR
          tpep_dropoff_datetime < tpep_pickup_datetime
GROUP BY vendorid;

-- o/p
--  	vendorid	no_of_records
-- 1	2	        14
-- 2	1	        74
-- As we can see the number of record which are out of range is around 88 and for VendorID 1 most number of records are faulty
-- So these records can be droppped

 
--  3. You might have encountered unusual or erroneous rows in the dataset.
--  Can you conclude which vendor is doing a bad job in providing the records using different columns of the dataset? 
--  Summarise your conclusions based on every column where these errors are present. For example,  There are unusual 
--  passenger count, i.e. 0 which is unusual
 
-- Lets identify all the records which are out of range
-- To Identify the Number of Null Data in the Dataset
SELECT 
    SUM(IF(VendorID IS NULL,1,0)) AS VendorID,
    SUM(IF(tpep_pickup_datetime IS NULL,1,0)) AS tpep_pickup_datetime,
    SUM(IF(tpep_dropoff_datetime IS NULL,1,0)) AS dropoff_datetime,
    SUM(IF(Passenger_count IS NULL,1,0)) AS Passenger_count,
    SUM(IF(Trip_distance IS NULL,1,0)) AS Trip_distance,
    SUM(IF(PULocationID IS NULL,1,0)) AS PULocationID,
    SUM(IF(DOLocationID IS NULL,1,0)) AS DOLocationID,
    SUM(IF(RateCodeID IS NULL,1,0)) AS RateCodeID,
    SUM(IF(Store_and_fwd_flag IS NULL,1,0)) AS Store_and_fwd_flag,
    SUM(IF(Payment_type IS NULL,1,0)) AS Payment_type,
    SUM(IF(Fare_amount IS NULL,1,0)) AS Fare_amount,
    SUM(IF(Extra IS NULL,1,0)) AS Extra,
    SUM(IF(MTA_tax IS NULL,1,0)) AS MTA_tax,
    SUM(IF(Improvement_surcharge IS NULL,1,0)) AS Improvement_surcharge,
    SUM(IF(Tip_amount IS NULL,1,0)) AS Tip_amount,
    SUM(IF(Tolls_amount IS NULL,1,0)) AS Tolls_amount,
    SUM(IF(Total_amount IS NULL,1,0)) AS Total_amount
FROM new_york_taxi;

-- o/p
--  	vendorid	tpep_pickup_datetime	dropoff_datetime	tpep_pickup_datetime	passenger_count	trip_distance	pulocationid	dolocationid	ratecodeid	store_and_fwd_flag	payment_type	fare_amount	extra	mta_tax	improvement_surcharge	tip_amount	tolls_amount	total_amount
-- 1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
-- As we can see there are no null records

-- Lets Identify the min and max of each columns and count for each features
SELECT min(VendorID) as min_val, max(VendorID) as max_val, count(distinct VendorID) as count_val
from new_york_taxi;
-- o/p
--  	min_val	max_val	count_val
-- 1	1	2	2
-- As we can see that there are only two values

-- Lets check with the Passenger Count Column
SELECT min(Passenger_count) as min_val, max(Passenger_count) as max_val, count(distinct Passenger_count) as count_val
from new_york_taxi;
-- o/p
--  	min_val	max_val	count_val
-- 1	0	9	10
-- We can see above that the min passenger count is 0 and max passenger count is 9
-- Lets check how many records are there for each Passenger Count

SELECT Passenger_count, count(*) as no_of_records
FROM new_york_taxi
GROUP BY Passenger_count
ORDER BY Passenger_count;
-- o/p
--  	passenger_count	no_of_records
-- 1	0	            6824
-- 2	1	            827499
-- 3	2	            176872
-- 4	3	            50693
-- 5	4	            24951
-- 6	5	            54568
-- 7	6	            33146
-- 8	7	            12
-- 9	8	            3
-- 10	9	            1

-- Conclusion Driven: 
-- 1. As it can be seen above that the there are some records which has Passenger Count as 0, there might be two reason
--      a. The Driver was not interested to feed in some details regaeding the number of Passenger Onboard
--      b. Or Someone just send some kind off item/parcell
-- 2. As we can see most amount of records are between passenger count 0-6, but anything above 6 the records are very less. 
--      a. So we can assume that the records entered were wrong, or really in some cars some more numbers of passenger onboard the cab because the cabs are big

-- Lets identify which vendors are providing the wrong details, lets take the passenger count which is error is 0
SELECT VendorID, Passenger_count, count(*) as no_of_records
FROM new_york_taxi
WHERE Passenger_count IN ( 0 , 7 , 8 , 9 )
GROUP BY VendorID, Passenger_count
ORDER BY Passenger_count;
-- o/p
--  	vendorid	passenger_count	no_of_records
-- 1	1	        0	            6813
-- 2	2	        0	            11
-- 3	2	        7	            11
-- 4	1	        7	            1
-- 5	2	        8	            3
-- 6	2	        9	            1
-- VendorID 1 has has more number of records where the passenger count is 0 and For Vendor ID 2 very less amount of records has passenger count as 0( So these records we can drop )
-- For the other passenger count > 6 which we can consider as the data points where the car was big

-- Lets now check for Trip Distance  
SELECT min(Trip_distance) as min_val, max(Trip_distance) as max_val, count(distinct Trip_distance) as count_val
from new_york_taxi;
-- o/p
--  	min_val	max_val	count_val
-- 1	0	    126.41	3192
-- As we can see the min value is 0 and max value is 126, so lets analyze some details about the trip distance is 0

SELECT * from new_york_taxi WHERE Trip_distance == 0;
-- o/p
-- new_york_taxi.vendorid	new_york_taxi.tpep_pickup_datetime	new_york_taxi.tpep_dropoff_datetime	new_york_taxi.passenger_count	new_york_taxi.trip_distance	new_york_taxi.ratecodeid	new_york_taxi.store_and_fwd_flag	new_york_taxi.pulocationid	new_york_taxi.dolocationid	new_york_taxi.payment_type	new_york_taxi.fare_amount	new_york_taxi.extra	new_york_taxi.mta_tax	new_york_taxi.tip_amount	new_york_taxi.tolls_amount	new_york_taxi.improvement_surcharge	new_york_taxi.total_amount
-- 2	2017-11-01 00:31:00.0	2017-11-01 00:31:00.0	1	0	1	N	193	193	2	2.5	0.5	0.5	0	0	0.3	3.8
-- 1	2017-11-01 00:19:00.0	2017-11-01 00:19:00.0	1	0	1	N	13	13	4	2.5	0.5	0.5	0	0	0.3	3.8
-- 1   2017-11-01 00:53:00.0	2017-11-01 00:54:00.0	1	0	1	N	48	48	3	3	0.5	0.5	0	0	0.3	4.3
-- 2	2017-11-01 00:34:00.0	2017-11-01 00:34:00.0	2	0	1	N	144	144	3	-2.5	-0.5	-0.5	0	0	-0.3	-3.8
-- 1	2017-11-01 01:24:00.0	2017-11-01 01:25:00.0	1	0	1	N	145	145	2	3	0.5	0.5	0	0	0.3	4.3
-- As we can see the total amount is there, but as we can see that the location id is also not changing, but there are some records where the localtion ID is changing but still the Trip Distance is 0

-- Lets improve the query and identify which records are faulty
SELECT tpep_pickup_datetime,tpep_dropoff_datetime  FROM new_york_taxi WHERE Trip_distance == 0 AND tpep_pickup_datetime != tpep_dropoff_datetime LIMIT 5;
-- o/p
--  	tpep_pickup_datetime	tpep_dropoff_datetime
-- 1	2017-11-01 00:53:00.0	2017-11-01 00:54:00.0
-- 2	2017-11-01 01:24:00.0	2017-11-01 01:25:00.0
-- 3	2017-11-01 01:22:00.0	2017-11-01 01:23:00.0
-- 4	2017-11-01 01:31:00.0	2017-11-01 01:39:00.0
-- 5	2017-11-01 02:51:00.0	2017-11-01 02:52:00.0
-- It might be possible that the Trip Distance is 0 because someone might have onboard the cab might have cancelled just after at the next min

-- Lets improvise the Query based on PULocationID and DOLocationID , if they are not same then the cab was running and with Payment_type if it is Credit Card, Cash
-- Credit Card in case someone has linked the Credit Card and as a Cancellation Fee and Cash in case Someone onboard the car and thought of cancelling because of some reason
SELECT Payment_type, COUNT(*) as no_of_record FROM new_york_taxi WHERE Trip_distance == 0 AND DOLocationID != PULocationID AND Payment_type IN ( 1, 2 ) GROUP BY Payment_type;
-- o/p
--  	payment_type	no_of_record
-- 1	2	            1315
-- 2	1	            932
-- As we can see the Location is changing and also the charge was deducted via Cash and Card

-- Lets Identify which vendor is at fault
SELECT VendorID, COUNT(*) as no_of_record FROM new_york_taxi 
WHERE Trip_distance == 0 AND DOLocationID != PULocationID AND Payment_type IN ( 1, 2 ) 
GROUP BY VendorID;
-- o/p
--  	vendorid	no_of_record
-- 1	2	1066
-- 2	1	1181
-- As it can be seen that the both the vendors are at equal fault

-- Lets Analyze RateCodeID
SELECT min(RateCodeID) as min_val, max(RateCodeID) as max_val, count(distinct RateCodeID) as count_val
from new_york_taxi;
-- o/p
--  	min_val	max_val	count_val
-- 1	1	99	7
-- As it can be seen that there are 7 distinct value and the maximum is 99 but as the Data Dictionary there are only 6 category and 99 is not a valid category

SELECT RateCodeID, count(*) as no_of_record
FROM new_york_taxi
GROUP BY RateCodeID 
ORDER BY RateCodeID;
-- o/p
--  	ratecodeid	no_of_record
-- 1	1	1142278
-- 2	2	25338
-- 3	3	2562
-- 4	4	586
-- 5	5	3793
-- 6	6	3
-- 7	99	9
-- So we can see 9 records are there which are not valid, so lets analyze by vendor id
SELECT VendorID, count(*) as no_of_record
FROM new_york_taxi
WHERE NOT RateCodeID BETWEEN 1 and 6
GROUP BY VendorID;
-- o/p
--  	vendorid	no_of_record
-- 1	2	1
-- 2	1	8
-- So for Vendor ID 1 most number of records are at fault, so we ignore this data points as they are faulty


-- Lets Analyze Store_and_fwd_flag
SELECT min(Store_and_fwd_flag) as min_val, max(Store_and_fwd_flag) as max_val, count(distinct Store_and_fwd_flag) as count_val
from new_york_taxi;
-- o/p
--  	min_val	max_val	count_val
-- 1	N	Y	2
-- So for this Feature the Data point looks good as there are only two types 

-- Lets analyze the Payment_type
SELECT min(Payment_type) as min_val, max(Payment_type) as max_val, count(distinct Payment_type) as count_val
FROM new_york_taxi;
-- o/p
--  	min_val	max_val	count_val
-- 1	1	4	4
-- As we can see there are only found kinds of Payment Type

-- Lets check out all the types
SELECT Payment_type, count(*) as no_of_record
FROM new_york_taxi
GROUP BY Payment_type
ORDER BY Payment_type;
-- o/p
--  	payment_type	no_of_record
-- 1	1	            790256
-- 2	2	            376374
-- 3	3	            6274
-- 4	4	            1665
-- As we can see there are records with only Payment Type from 1-4, so there is no fault in this Feature

-- Lets Check the Fare_amount
SELECT min(Fare_amount) as min_val, max(Fare_amount) as max_val, count(distinct Fare_amount) as count_val
FROM new_york_taxi;
-- o/p
--  	min_val	max_val	count_val
-- 1	-200	650	    676
-- As we can see the min amount is -200 and 650

-- Lets Try to get the Percentile Values to see the Distribution, 0, 10, 25, 50, 75, 90, 100
SELECT round(perc_val,2) as Percentile_val
FROM (  SELECT explode(percentile_approx( Fare_amount, array(0.05, 0.1, 0.25, 0.75, 0.9, 0.99 ))) as perc_val
        FROM new_york_taxi) temp_table;
-- o/p
--  	percentile_val
-- 1	4.31
-- 2	4.94
-- 3	6.41
-- 4	14.5
-- 5	24.85
-- 6	51.96
-- As we can see above all the percentile value, the Fare_amount range

-- Lets Identify the range of the data
SELECT round(perc_val,2) as Percentile_val
FROM (  SELECT explode(percentile_approx( Fare_amount, array(0.01 , 0.99))) as perc_val
        FROM new_york_taxi ) temp_table;

-- o/p        
--  	percentile_val
-- 1	3.26
-- 2	51.96
-- So Clearly -200 and 650 are outlier

SELECT Fare_amount
FROM new_york_taxi
WHERE NOT Fare_amount between 3 and 52
ORDER BY Fare_amount LIMIT 10;
-- o/p
-- fare_amount
-- -200
-- -175
-- -115.55
-- -90
-- -79
-- -73.11
-- -58.56
-- -52
-- -52

-- So these dat are clearly an outlier, so lets see which Vendor has provided these data and lets increase the limit from 1 to 100
SELECT VendorID, count(*) as no_of_record
FROM new_york_taxi
WHERE round(Fare_amount) < 0 OR ( round(Fare_amount) > 53 AND Trip_distance == 0 ) 
GROUP BY VendorID;
-- o/p
--  	vendorid	no_of_record
-- 1	2	        1130
-- 2	1	        205
-- Here the Vendor ID 2 has most number of fault records
-- Reason for the where Condition, the Fare Amount < 0 usually that is a wrong case
-- And if the Fare is > 53 , there are two possible scenarios
--      a. Sometimes the surcharge is huge or some factors are huge because of which the Fare is high ( travel at night/dawn, events, traffic time )
--      b. But for all of the Trip_Distance can't be Zero, that's a faulty record

-- Lets look for the Field Extra
SELECT min(Extra) as min_val, max(Extra) as max_val, count(distinct Extra) as count_val
FROM new_york_taxi;
-- o/p
--  	min_val	max_val	count_val
-- 1	-10.6	4.8	14

-- Lets check the Value Counts of Different Extra Values
SELECT  Extra, count(*) as no_of_record
FROM new_york_taxi
GROUP BY Extra
ORDER BY Extra;
-- o/p
--  	extra	no_of_record
-- 1	-10.6	1
-- 2	-4.5	5
-- 3	-1	    87
-- 4	-0.5	193
-- 5	0	    631872
-- 6	0.3	    36
-- 7	0.5	    363455
-- 8	0.8	    15
-- 9	1	    174386
-- 10	1.3	    13
-- 11	1.5	    2
-- 12	2	    1
-- 13	4.5	    4502
-- 14	4.8	    1
-- As we can see there are Some Negative Value, As per the Data Dictionaly $0.05 and $0.01 are the rush hour Surcharges and rest all are midnight surcharge
-- a. For -10.6 clearly that seems like a Manual Mistake
-- b. For other negative values there exists some positive values so these also looks like a manual mistake , so only a sign change can be done on these values to rectify the same

-- Lets Check which Vendor Has given most amount of faulty Records
SELECT VendorID, count(*) as no_of_record
FROM new_york_taxi
WHERE Extra < 0
GROUP BY VendorID;
-- o/p
--  	vendorid	no_of_record
-- 1	2	        285
-- 2	1	        1
-- As we can see above for VendorID 2, most number number of Faulty records are present

-- Lets Check for MTA_tax
SELECT min(MTA_tax) as min_val, max(MTA_tax) as max_val, count(distinct MTA_tax) as count_val
from new_york_taxi;
-- o/p
--  	min_val	max_val	count_val
-- 1	-0.5	11.4	5
-- As per the Data Dictionary there is a $0.50 MTA tax that is automatically triggered based on the metered rate in use.

-- Lets check the Value Counts
SELECT MTA_tax, count(*) as no_of_records
FROM new_york_taxi
GROUP BY MTA_tax
ORDER BY MTA_tax;
-- o/p
--  	mta_tax	no_of_records
-- 1	-0.5	544
-- 2	0	    5197
-- 3	0.5	    1168824
-- 4	3	    3
-- 5	11.4	1
-- As we can see above
--  1. Only Two possible Values are possible 0/0.5
--  2. -0.5 seems like a manual mistake for 0.5 ( So sign can be taken care of )
--  3. 3 and 11.4 completely looks illogical here

-- lets identify which Vendor is at fault here
SELECT vendorid, count(*) as no_of_record
FROM new_york_taxi
WHERE MTA_tax NOT IN ( 0 , 0.5)
GROUP BY VendorID;
-- o/p
--  	vendorid	no_of_record
-- 1	2	        547
-- 2	1	        1
-- As we can see for VendorID 2 more number of records are faulty

-- Lets Look for Improvement_surcharge
SELECT min(Improvement_surcharge) as min_val, max(Improvement_surcharge) as max_val, count(distinct Improvement_surcharge) as count_val
from new_york_taxi;
-- o/p
--  	min_val	max_val	count_val
-- 1	-0.3	1	4
-- As per the data dictionary $0.30 improvement surcharge assessed trips at the flag drop, so lets Have Some more look on the data points

-- Value Counts
SELECT Improvement_surcharge,count(*) as no_of_record
FROM new_york_taxi
GROUP BY Improvement_surcharge
ORDER by Improvement_surcharge;
-- o/p
--  	improvement_surcharge	no_of_record
-- 1	-0.3	                558
-- 2	0	                    287
-- 3	0.3	                    1173720
-- 4	1	                    4
-- As it can be seen from above o/p
--      a. 0 and 0.3 are the correct records
--      b. -0.3 seems like a manual mistake in place of 0.3 they have wrongly inserted the data to that needs to be taken care of ( change of Sign )
--      c. But 1 is clearly an error as per the data Dictionary
SELECT vendorid, count(*) as no_of_record
FROM new_york_taxi
WHERE Improvement_surcharge NOT IN ( 0 , 0.3)
GROUP BY VendorID;
-- o/p
--  	vendorid	no_of_record
-- 1	2	562
-- Vendor ID 2 has provided the faulty records in the current case

-- Let check for Tip_amount
SELECT min(Tip_amount) as min_val, max(Tip_amount) as max_val, count(distinct Tip_amount) as count_val
from new_york_taxi;
-- o/p
--  	min_val	max_val	count_val
-- 1	-1.16	450	2133
-- Here the Data Range looks quite Diverse, lets try to get all the percentile values

SELECT round(perc_val,2) as Percentile_val
FROM (  SELECT explode(percentile_approx( Tip_amount, array(0.05, 0.1, 0.25, 0.75, 0.9, 0.99 ))) as perc_val
        FROM new_york_taxi) temp_table;
-- o/p
--  	percentile_val
-- 1	-0.57
-- 2	-0.47
-- 3	-0.2
-- 4	2.45
-- 5	4.24
-- 6	11.71
-- As we can see till 25Percentile we have negative values, but as we know the tip amount can't be negative, putting aside those values lets identify the range

SELECT round(perc_val,2) as Percentile_val
FROM (  SELECT explode(percentile_approx( Tip_amount, array(0.5, 0.75, 0.9, 0.99 ))) as perc_val
        FROM new_york_taxi WHERE Tip_amount >= 0 ) temp_table;
-- o/p
--  	percentile_val
-- 1	1.35
-- 2	2.45
-- 3	4.24
-- 4	11.71
-- As we can see most of the data lie between the range 0 to 12, others are outliers, lets check how many such records are there. Negative values are possible to be a manual mistake

SELECT Tip_amount, count(*) as no_records
FROM new_york_taxi
WHERE Tip_amount NOT BETWEEN 0 and 12  AND Payment_type != 1
GROUP BY Tip_amount
ORDER BY Tip_amount DESC; 
-- o/p
--  	tip_amount	no_records
-- 1	-0.66	1
-- 2	-0.82	1
-- 3	-0.86	1
-- 4	-1.16	1
-- As the Tip Amount Can't be negative and also the Payment Type is from Credit Card only, so these are the faulty record
-- And as a Tip Amount can be as large as possible so there we can't put any restrictions

-- Lets check for which VendorID gave wrong data
SELECT vendorid, count(*) as no_of_record
FROM new_york_taxi
WHERE Tip_amount NOT BETWEEN 0 and 12  AND Payment_type != 1
GROUP BY VendorID;
-- o/p
--  	vendorid	no_of_record
-- 1	2	        4
-- For VendorID 2 more number number of records are faulty

-- lets check for Tolls Amount
SELECT min(Tolls_amount) as min_val, max(Tolls_amount) as max_val, count(distinct Tolls_amount) as count_val
from new_york_taxi;
-- o/p
--   minimum    maximum    unique
-- 1 -5.76    895.89    369
-- There are some Negative Values

SELECT round(perc_val,2) as Percentile_val
FROM (  SELECT explode(percentile_approx( Tolls_amount, array(0.05, 0.1, 0.25, 0.75, 0.9, 0.99 ))) as perc_val
       FROM new_york_taxi) temp_table;
-- o/p
--  	percentile_val
-- 1	-5.46
-- 2	-5.15
-- 3	-4.24
-- 4	-1.2
-- 5	-0.29
-- 6	5.76

-- As it can be seen above that most of the records are below 5.76, lets identify the count
-- As we can see the approximate values are between 

SELECT Tolls_amount, count(*) as no_of_records
FROM new_york_taxi
GROUP BY Tolls_amount
HAVING count(*) > 100 
ORDER BY Tolls_amount DESC;
-- o/p
--  	tolls_amount	no_of_records
-- 1	17.5	        160
-- 2	15.5	        122
-- 3	12.5	        627
-- 4	11.52	        275
-- 5	10.5	        983
-- 6	5.76	        56086
-- 7	5.54	        379
-- 8	2.64	        560
-- 9	0	            1113349

-- As we can see there are large number of data at 5.76 & 0, that's why the percentile approx is coming like this 
-- Lets Try to check the extreme case and the minimum case
-- Minimum case ( If the value is less than 0 )

-- Lets check how many records are there below zero
SELECT `bucket` , count(*) as no_of_record 
FROM ( SELECT CASE
        WHEN Tolls_amount < 0 THEN 1
        WHEN ( Tolls_amount >= 0 and Tolls_amount < 50 ) THEN 2
        WHEN ( Tolls_amount >= 50 and Tolls_amount < 100 ) THEN 3
        WHEN ( Tolls_amount >= 100 and Tolls_amount < 150 ) THEN 4
        WHEN ( Tolls_amount >= 150 and Tolls_amount < 200 ) THEN 5
        else 6 end `bucket`
FROM new_york_taxi ) temp_table
GROUP BY `bucket`
ORDER BY `bucket`;
-- o/p
--  	bucket	no_of_record
-- 1	1	3
-- 2	2	1174544
-- 3	3	18
-- 4	4	2
-- 5	6	2

-- As we can see above what we tried to do is bucket/bin the data in some bracket,
-- so th brackets where if less 0 ==> 1, if between 0 and 50 then ==> 2, if between 50 and 100 then ==> 3, if between 100 and 150 then ==> 4 and if betwen 150 and 200 ==> 5 and rest as 6
-- So we can see above there are very less record which is negative and which are above 150, lets try to have a look on those values


SELECT Tolls_amount, count(*) as number_of_record 
FROM new_york_taxi
WHERE Tolls_amount < 0 or Tolls_amount >= 100
GROUP BY Tolls_amount
ORDER BY Tolls_amount DESC ; 
-- o/p
--  	tolls_amount	number_of_record
-- 1	895.89	        1
-- 2	200	            1
-- 3	125.76	        1
-- 4	101.1	        1
-- 5	-5.76	        3
-- As we can see for the Numbers like 200 and 895.89 looks like a manual mistake because they are extremely high, but for 5.76 this is a sign problem 
-- For 125.76 and 101.1 they doesn't look like a madeup number
-- Lets try to have a look for >100 tolls amount data and understand some key things 

SELECT trip_distance, Tolls_amount  FROM new_york_taxi WHERE Tolls_amount > 100 OR Tolls_amount < 0
ORDER BY Tolls_amount DESC;
-- o/p
--  	trip_distance	tolls_amount
-- 1	9.2	            895.89
-- 2	16.8	        200
-- 3	25.4	        125.76
-- 4	0	            101.1
-- 5	0.22	        -5.76
-- 6	0.05	        -5.76
-- 7	0.03	        -5.76
-- As we can see these are the trip distance and for 895.89, 200, 101.1 looks like a wrong data and for -5.76 this also looks like a sign problem

SELECT vendorid, count(*) as number_of_record 
FROM new_york_taxi
WHERE Tolls_amount < 0 OR Tolls_amount >= 200 OR Tolls_amount ==  101.1
GROUP BY vendorid; 
-- o/p
--  	vendorid	number_of_record
-- 1	2	        3
-- 2	1	        3
-- Both the vendors looks like equally responsible

-- Lets Check for Total_amount       
SELECT min(Total_amount) as min_val, max(Total_amount) as max_val, count(distinct Total_amount) as count_val
from new_york_taxi;
-- o/p
--  	min_val	max_val	count_val
-- 1	-200.8	928.19	6115

-- lets check the price distribution
SELECT round(perc_val,2) as Percentile_val
FROM (  SELECT explode(percentile_approx( Total_amount, array(0.05, 0.1, 0.25, 0.75, 0.9, 0.99 ))) as perc_val
       FROM new_york_taxi) temp_table;
-- o/p
--  	percentile_val
-- 1	5.79
-- 2	6.79
-- 3	8.74
-- 4	17.8
-- 5	30.06
-- 6	70.27

-- This shows the approx percentile distribution, but as we can see the min and max are quite far , i.e the range is quite high, so lets idenitfy what are the anomaly data
-- lets check how many negative records are there

SELECT count(*) as number_of_record
FROM new_york_taxi
WHERE Total_amount < 0;

-- o/p
--  	number_of_record
-- 1	558
-- There are some record which are less than 0 so we need to handle these record, these are wrong data

-- And lets check the outliers on the upper bound
SELECT `bucket` , count(*) as no_of_record 
FROM ( SELECT CASE
        WHEN Total_amount < 0 THEN 1
        WHEN ( Total_amount >= 0 and Tolls_amount < 100 ) THEN 2
        WHEN ( Total_amount >= 100 and Tolls_amount < 200 ) THEN 3
        WHEN ( Total_amount >= 200 and Tolls_amount < 350 ) THEN 4
        WHEN ( Total_amount >= 300 and Tolls_amount < 400 ) THEN 5
        else 6 end `bucket`
FROM new_york_taxi ) temp_table
GROUP BY `bucket`
ORDER BY `bucket`;
-- o/p
--  	bucket	no_of_record
-- 1	1	    558
-- 2	2	    1174007
-- 3	3   	2
-- 4	4	    1
-- 5	6	    1
-- As we can see above there are around 4 data points which has total amount > 200

SELECT vendorid, count(*) as number_of_record 
FROM new_york_taxi
WHERE Total_amount < 0 OR Total_amount > 200
GROUP BY vendorid; 
-- o/p
--  	vendorid	number_of_record
-- 1	2	668
-- 2	1	59

-- As we can see more number Vendor 2 have provided more number of wrong Data

-- You might have encountered unusual or erroneous rows in the dataset. Can you conclude which vendor is doing a bad job in providing 
-- the records using different columns of the dataset? Summarise your conclusions based on every column where these errors are present. 
-- For example,  There are unusual passenger count, i.e. 0 which is unusual.

-- Conclusion


--1. Compare the overall average fare per trip for November and December.

select month(from_unixtime(unix_timestamp( tpep_pickup_datetime, 'yyyy-MM-dd HH:mm:ss'))) as mnth,
avg(Total_amount) as avg_fare from new_york_taxi
group by month(from_unixtime(unix_timestamp( tpep_pickup_datetime, 'yyyy-MM-dd HH:mm:ss')));

--  Month | Average Fare
-- 	12	  | 16.148044600224704
--  11	  | 16.446918576574948

-- 2.Explore the ‘number of passengers per trip’ - 
--   how many trips are made by each level of ‘Passenger_count’? Do most people travel solo or with other people?

select Passenger_count, count(*) as trip_counts from new_york_taxi
group by Passenger_count
order by trip_counts desc;

-- passenger_count||trip_counts
    -- 1       	    827499
    -- 2	        176872
    -- 5	        54568
    -- 3	        50693
    -- 6	        33146
    -- 4	        24951
    -- 0	        6824
    -- 7	        12

-- As we see most of the rides are taken by solo passengers.

-- 3. Which is the most preferred mode of payment?

select Payment_type, count(Payment_type) as Counts from new_york_taxi
group by Payment_type
order by Counts desc;

-- payment_type || counts
--     1       	    790256
--     2	        376374
--     3	        6274
--     4	        1665

-- We can see major transaction is done with the payment mode 1 i.e., Credit Card.

-- 4. What is the average tip paid per trip? Compare the average tip with the 
-- 25th, 50th and 75th percentiles and comment whether the ‘average tip’ is a representative statistic (of the central tendency) 
-- of ‘tip amount paid’. Hint: You may use percentile_approx(DOUBLE col, p): 
-- Returns an approximate pth percentile of a numeric column (including floating point types) in the group.

select percentile_approx(Tip_amount, 0.25) as 25th_percentile,
percentile_approx(Tip_amount, 0.50) as 50th_percentile,
percentile_approx(Tip_amount, 0.75) as 75th_percentile
from new_york_taxi

-- 5. Explore the ‘Extra’ (charge) variable - what fraction of total trips have an extra charge is levied?
with ft as (select VendorID,
case when Extra > 0 then Extra end as charged,
case when Extra = 0 then Extra end as not_charged
from new_york_taxi)

select count(charged) as charged, count(not_charged) not_charged, 
count(charged)/(count(charged) + count(not_charged)) as fraction
from ft;

-- charged | not_charged    | fraction
-- 542411  	 631872	          0.4619082452866983