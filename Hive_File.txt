-- Adding the jar file 
ADD JAR /opt/cloudera/parcels/CDH/lib/hive/lib/hive-hcatalog-core-1.1.0-cdh5.11.2.jar;

-- PARTITION THE DATA  
-- IMPORTANT: BEFORE PARTITIONING ANY TABLE,
SET hive.exec.max.dynamic.partitions=100000;
SET hive.exec.max.dynamic.partitions.pernode=100000;

-- Delete Table if already exists
DROP TABLE new_york_taxi;

-- Create Table 
create external table if not exists new_york_taxi
(
VendorID int,
tpep_pickup_datetime timestamp, 
tpep_dropoff_datetime timestamp,
Passenger_count int,
Trip_distance double,
RateCodeID int, 
Store_and_fwd_flag string, 
PULocationID string, 
DOLocationID string,
Payment_type int,
Fare_amount double, 
Extra double,
MTA_tax double,
Tip_amount double,
Tolls_amount double,
Improvement_surcharge double,
Total_amount double)
ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
location '/common_folder/nyc_taxi_data'
tblproperties("skip.header.line.count"="1");

-- To Check whether the Data was imported properly or not
SELECT * from new_york_taxi limit 5;

-- o/p: of the Query
-- new_york_taxi.vendorid	new_york_taxi.tpep_pickup_datetime	new_york_taxi.tpep_dropoff_datetime	new_york_taxi.passenger_count	new_york_taxi.trip_distance	new_york_taxi.pulocationid	new_york_taxi.dolocationid	new_york_taxi.ratecodeid	new_york_taxi.store_and_fwd_flag	new_york_taxi.payment_type	new_york_taxi.fare_amount	new_york_taxi.extra	new_york_taxi.mta_tax	new_york_taxi.improvement_surcharge	new_york_taxi.tip_amount	new_york_taxi.tolls_amount	new_york_taxi.total_amount
-- 1	01-11-17 00:01:00.0	01-11-17 00:03:00.0	1	0.4	1	N	151	151	2	3.5	    0.5	0.5	0	    0	0.3	4.8
-- 2	01-11-17 00:31:00.0	01-11-17 00:31:00.0	1	0	1	N	193	193	2	2.5	    0.5	0.5	0	    0	0.3	3.8
-- 1	01-11-17 00:25:00.0	01-11-17 00:40:00.0	1	2.9	1	N	50	249	1	12.5	0.5	0.5	2.75	0	0.3	16.55
-- 1	01-11-17 00:17:00.0	01-11-17 00:30:00.0	1	3	1	N	79	230	1	11.5	0.5	0.5	2.55	0	0.3	15.35
-- 1	01-11-17 00:38:00.0	01-11-17 01:01:00.0	1	4.2	1	N	113	33	1	18.5	0.5	0.5	3.95	0	0.3	23.75



-- Part I :Basic Data Quality Checks
-- 1. How many records has each TPEP provider provided? Write a query that summarises the number of records of each provider.
SELECT VendorID , count(*) as no_of_record 
from new_york_taxi
group by VendorID;

-- o/p
--  	| vendorid	| no_of_record
-- 1	| 2	        | 647183
-- 2	| 1	        | 527386
-- So for Creative Mobile Technologies : 527386 ( No of Records ) and for VeriFone Inc. : 647183 (No of Records )


-- 2. The data provided is for months November and December only. Check whether the data is consistent, and if not, 
-- identify the data quality issues. Mention all data quality issues in comments.
-- Lets the Data Distribution based on Month and Year ( As this will help to partition the Data
-- The data is for the two months Nov 2017 and Dec 2017
SELECT 
year(from_unixtime(unix_timestamp( tpep_pickup_datetime))) AS year_in_dat , 
month(from_unixtime(unix_timestamp( tpep_pickup_datetime))) as month_in_dat,
count(*) as Number_of_Records
from new_york_taxi
group by year(from_unixtime(unix_timestamp( tpep_pickup_datetime))),
         month(from_unixtime(unix_timestamp( tpep_pickup_datetime)));

-- o/p: of the Query         
-- year_in_dat	month_in_dat	number_of_records
-- 2003	1	1
-- 2008	12	2
-- 2009	1	1
-- 2017	11	580300
-- 2017	10	6
-- 2017	12	594255
-- 2018	1	4
-- 
-- As we can see Below some Data are of year 2003, 2008, 2009 ( so these are the data which is not relevant for the current use case )
-- But some data are also there of Oct 2017 and Jan 2018, this is like the Trip started around Midnight
-- So lets Analyze some more Data where the Year is 2017 and month is 10 and year is 2018 and the month is 1
-- Idea is get all the record whose pickup is at 31st Oct 2017 and 1st Jan 2018 and Drop off Time is in 31st October 2017 and
-- Drop Off Time > 1st Jan 2018
SELECT
tpep_pickup_datetime ,
tpep_dropoff_datetime
FROM new_york_taxi
WHERE ( year(from_unixtime(unix_timestamp( tpep_pickup_datetime))) == 2017 AND 
        month(from_unixtime(unix_timestamp( tpep_pickup_datetime))) == 10 ) OR
      ( year(from_unixtime(unix_timestamp( tpep_pickup_datetime))) == 2018 AND 
        month(from_unixtime(unix_timestamp( tpep_pickup_datetime))) == 1 ) OR 
      ( year(from_unixtime(unix_timestamp( tpep_dropoff_datetime))) == 2017 AND 
        month(from_unixtime(unix_timestamp( tpep_dropoff_datetime))) == 10 ) OR
      ( year(from_unixtime(unix_timestamp( tpep_dropoff_datetime))) == 2018 AND 
        month(from_unixtime(unix_timestamp( tpep_dropoff_datetime))) == 1  AND day(from_unixtime(unix_timestamp( tpep_dropoff_datetime))) > 1 );    
ORDER BY from_unixtime(unix_timestamp( tpep_pickup_datetime));

-- As we can see below there are around 10 records, out of which for 6 records the pickup time is on 31st October 2017 and 4 records for whom the pickup time is  at 1st Jan 2018
--  	tpep_pickup_datetime	tpep_dropoff_datetime
-- 1	2017-10-31 11:23:00.0	2017-10-31 11:28:00.0
-- 2	2017-10-31 18:33:00.0	2017-10-31 18:38:00.0
-- 3	2017-10-31 18:56:00.0	2017-11-01 18:18:00.0
-- 4	2017-10-31 23:59:00.0	2017-11-01 00:10:00.0
-- 5	2017-10-31 23:59:00.0	2017-11-01 00:06:00.0
-- 6	2017-10-31 23:59:00.0	2017-11-01 00:11:00.0
-- 7	2018-01-01 00:00:00.0	2018-01-01 00:00:00.0
-- 8	2018-01-01 00:00:00.0	2018-01-01 00:15:00.0
-- 9	2018-01-01 00:00:00.0	2018-01-01 00:12:00.0
-- 10	2018-01-01 00:04:00.0	2018-01-01 00:17:00.0
-- So these records are also not valid

-- So lets identify how many records are out of range 
SELECT tpep_pickup_datetime, tpep_dropoff_datetime  
FROM new_york_taxi
WHERE NOT ( tpep_pickup_datetime BETWEEN '2017-11-01 00:00:00.0' AND '2017-12-31 23:59:59.0' AND 
          tpep_dropoff_datetime BETWEEN '2017-11-01 00:00:00.0' AND '2018-01-01 23:59:59.0' )
order by tpep_pickup_datetime, tpep_dropoff_datetime;

-- o/p
--  	tpep_pickup_datetime	tpep_dropoff_datetime
-- 1	2003-01-01 00:58:00.0	2003-01-01 01:28:00.0
-- 2	2008-12-31 10:27:00.0	2008-12-31 10:48:00.0
-- 3	2008-12-31 23:53:00.0	2009-01-01 00:03:00.0
-- 4	2009-01-01 00:13:00.0	2009-01-01 00:32:00.0
-- 5	2017-10-31 11:23:00.0	2017-10-31 11:28:00.0
-- 6	2017-10-31 18:33:00.0	2017-10-31 18:38:00.0
-- 7	2017-10-31 18:56:00.0	2017-11-01 18:18:00.0
-- 8	2017-10-31 23:59:00.0	2017-11-01 00:06:00.0
-- 9	2017-10-31 23:59:00.0	2017-11-01 00:10:00.0
-- 10	2017-10-31 23:59:00.0	2017-11-01 00:11:00.0
-- 11	2017-11-14 13:50:00.0	2019-04-24 19:21:00.0
-- 12	2018-01-01 00:00:00.0	2018-01-01 00:00:00.0
-- 13	2018-01-01 00:00:00.0	2018-01-01 00:12:00.0
-- 14	2018-01-01 00:00:00.0	2018-01-01 00:15:00.0
-- 15	2018-01-01 00:04:00.0	2018-01-01 00:17:00.0
-- Above are the records which are not in range out of that there is a peculiar record, 11th Record of the above output,
-- where the droptime stamp is at 2019

-- Lets see whether the dropofftime is less than pickup time or not
SELECT count(*) as no_of_records 
FROM new_york_taxi
WHERE  tpep_dropoff_datetime < tpep_pickup_datetime;
-- o/p
--  	no_of_records
-- 1	73
-- Number of records are around 73 for which the drop off time is less than pickup time

-- Lets check some more information
SELECT * 
FROM new_york_taxi
WHERE  tpep_dropoff_datetime < tpep_pickup_datetime
LIMIT 5;
-- o/p
--  	new_york_taxi.vendorid	new_york_taxi.tpep_pickup_datetime	new_york_taxi.tpep_dropoff_datetime	new_york_taxi.passenger_count	new_york_taxi.trip_distance	new_york_taxi.ratecodeid	new_york_taxi.store_and_fwd_flag	new_york_taxi.pulocationid	new_york_taxi.dolocationid	new_york_taxi.payment_type	new_york_taxi.fare_amount	new_york_taxi.extra	new_york_taxi.mta_tax	new_york_taxi.tip_amount	new_york_taxi.tolls_amount	new_york_taxi.improvement_surcharge	new_york_taxi.total_amount
-- 1	1	2017-11-05 01:58:00.0	2017-11-05 01:02:00.0	1	0.3	1	N	264	264	1	4	0.5	0.5	1.05	0	0.3	6.35
-- 2	1	2017-11-05 01:58:00.0	2017-11-05 01:10:00.0	1	2.1	1	N	234	48	1	10	0.5	0.5	2	0	0.3	13.3
-- 3	1	2017-11-05 01:27:00.0	2017-11-05 01:09:00.0	2	15.7	1	N	140	14	2	47	0.5	0.5	0	0	0.3	48.3
-- 4	1	2017-11-05 01:58:00.0	2017-11-05 01:14:00.0	1	3.3	1	N	249	142	1	13.5	0.5	0.5	2	0	0.3	16.8
-- 5	1	2017-11-05 01:45:00.0	2017-11-05 01:27:00.0	1	9	1	N	148	61	1	33.5	0.5	0.5	8.7	0	0.3	43.5
-- As we can see for the above records drop off time is less than pick up time
-- Location is Changing
-- Customer has also paid ( as we can see the total amount of paid )
-- So these records looks has some fault

-- Lets check out how many such records are there and for which vendor the most number of error data are present
SELECT vendorid, count(*) no_of_records
FROM new_york_taxi
WHERE NOT ( tpep_pickup_datetime BETWEEN '2017-11-01 00:00:00.0' AND '2017-12-31 23:59:59.0' AND 
          tpep_dropoff_datetime BETWEEN '2017-11-01 00:00:00.0' AND '2018-01-01 23:59:59.0' ) OR
          tpep_dropoff_datetime < tpep_pickup_datetime
GROUP BY vendorid;

-- o/p
--  	vendorid	no_of_records
-- 1	2	        14
-- 2	1	        74
-- As we can see the number of record which are out of range is around 88 and for VendorID 1 most number of records are faulty
-- So these records can be droppped

 
--  3. You might have encountered unusual or erroneous rows in the dataset.
--  Can you conclude which vendor is doing a bad job in providing the records using different columns of the dataset? 
--  Summarise your conclusions based on every column where these errors are present. For example,  There are unusual 
--  passenger count, i.e. 0 which is unusual
 
-- Lets identify all the records which are out of range
-- To Identify the Number of Null Data in the Dataset
SELECT 
    SUM(IF(VendorID IS NULL,1,0)) AS VendorID,
    SUM(IF(tpep_pickup_datetime IS NULL,1,0)) AS tpep_pickup_datetime,
    SUM(IF(tpep_dropoff_datetime IS NULL,1,0)) AS dropoff_datetime,
    SUM(IF(Passenger_count IS NULL,1,0)) AS Passenger_count,
    SUM(IF(Trip_distance IS NULL,1,0)) AS Trip_distance,
    SUM(IF(PULocationID IS NULL,1,0)) AS PULocationID,
    SUM(IF(DOLocationID IS NULL,1,0)) AS DOLocationID,
    SUM(IF(RateCodeID IS NULL,1,0)) AS RateCodeID,
    SUM(IF(Store_and_fwd_flag IS NULL,1,0)) AS Store_and_fwd_flag,
    SUM(IF(Payment_type IS NULL,1,0)) AS Payment_type,
    SUM(IF(Fare_amount IS NULL,1,0)) AS Fare_amount,
    SUM(IF(Extra IS NULL,1,0)) AS Extra,
    SUM(IF(MTA_tax IS NULL,1,0)) AS MTA_tax,
    SUM(IF(Improvement_surcharge IS NULL,1,0)) AS Improvement_surcharge,
    SUM(IF(Tip_amount IS NULL,1,0)) AS Tip_amount,
    SUM(IF(Tolls_amount IS NULL,1,0)) AS Tolls_amount,
    SUM(IF(Total_amount IS NULL,1,0)) AS Total_amount
FROM new_york_taxi;

-- o/p
--  	vendorid	tpep_pickup_datetime	dropoff_datetime	tpep_pickup_datetime	passenger_count	trip_distance	pulocationid	dolocationid	ratecodeid	store_and_fwd_flag	payment_type	fare_amount	extra	mta_tax	improvement_surcharge	tip_amount	tolls_amount	total_amount
-- 1	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0
-- As we can see there are no null records

-- Lets Identify the min and max of each columns and count for each features
SELECT min(VendorID) as min_val, max(VendorID) as max_val, count(distinct VendorID) as count_val
from new_york_taxi;
-- o/p
--  	min_val	max_val	count_val
-- 1	1	2	2
-- As we can see that there are only two values

-- Lets check with the Passenger Count Column
SELECT min(Passenger_count) as min_val, max(Passenger_count) as max_val, count(distinct Passenger_count) as count_val
from new_york_taxi;
-- o/p
--  	min_val	max_val	count_val
-- 1	0	9	10
-- We can see above that the min passenger count is 0 and max passenger count is 9
-- Lets check how many records are there for each Passenger Count

SELECT Passenger_count, count(*) as no_of_records
FROM new_york_taxi
GROUP BY Passenger_count
ORDER BY Passenger_count;
-- o/p
--  	passenger_count	no_of_records
-- 1	0	            6824
-- 2	1	            827499
-- 3	2	            176872
-- 4	3	            50693
-- 5	4	            24951
-- 6	5	            54568
-- 7	6	            33146
-- 8	7	            12
-- 9	8	            3
-- 10	9	            1

-- Conclusion Driven: 
-- 1. As it can be seen above that the there are some records which has Passenger Count as 0, there might be two reason
--      a. The Driver was not interested to feed in some details regaeding the number of Passenger Onboard
--      b. Or Someone just send some kind off item/parcell
-- 2. As we can see most amount of records are between passenger count 0-6, but anything above 6 the records are very less. 
--      a. So we can assume that the records entered were wrong, or really in some cars some more numbers of passenger onboard the cab because the cabs are big

-- Lets identify which vendors are providing the wrong details, lets take the passenger count which is error is 0
SELECT VendorID, Passenger_count, count(*) as no_of_records
FROM new_york_taxi
WHERE Passenger_count IN ( 0 , 7 , 8 , 9 )
GROUP BY VendorID, Passenger_count
ORDER BY Passenger_count;
-- o/p
--  	vendorid	passenger_count	no_of_records
-- 1	1	        0	            6813
-- 2	2	        0	            11
-- 3	2	        7	            11
-- 4	1	        7	            1
-- 5	2	        8	            3
-- 6	2	        9	            1
-- VendorID 1 has has more number of records where the passenger count is 0 and For Vendor ID 2 very less amount of records has passenger count as 0( So these records we can drop )
-- For the other passenger count > 6 which we can consider as the data points where the car was big

-- Lets now check for Trip Distance  
SELECT min(Trip_distance) as min_val, max(Trip_distance) as max_val, count(distinct Trip_distance) as count_val
from new_york_taxi;
-- o/p
--  	min_val	max_val	count_val
-- 1	0	    126.41	3192
-- As we can see the min value is 0 and max value is 126, so lets analyze some details about the trip distance is 0

SELECT * from new_york_taxi WHERE Trip_distance == 0;
-- o/p
-- new_york_taxi.vendorid	new_york_taxi.tpep_pickup_datetime	new_york_taxi.tpep_dropoff_datetime	new_york_taxi.passenger_count	new_york_taxi.trip_distance	new_york_taxi.ratecodeid	new_york_taxi.store_and_fwd_flag	new_york_taxi.pulocationid	new_york_taxi.dolocationid	new_york_taxi.payment_type	new_york_taxi.fare_amount	new_york_taxi.extra	new_york_taxi.mta_tax	new_york_taxi.tip_amount	new_york_taxi.tolls_amount	new_york_taxi.improvement_surcharge	new_york_taxi.total_amount
-- 2	2017-11-01 00:31:00.0	2017-11-01 00:31:00.0	1	0	1	N	193	193	2	2.5	0.5	0.5	0	0	0.3	3.8
-- 1	2017-11-01 00:19:00.0	2017-11-01 00:19:00.0	1	0	1	N	13	13	4	2.5	0.5	0.5	0	0	0.3	3.8
-- 1   2017-11-01 00:53:00.0	2017-11-01 00:54:00.0	1	0	1	N	48	48	3	3	0.5	0.5	0	0	0.3	4.3
-- 2	2017-11-01 00:34:00.0	2017-11-01 00:34:00.0	2	0	1	N	144	144	3	-2.5	-0.5	-0.5	0	0	-0.3	-3.8
-- 1	2017-11-01 01:24:00.0	2017-11-01 01:25:00.0	1	0	1	N	145	145	2	3	0.5	0.5	0	0	0.3	4.3
-- As we can see the total amount is there, but as we can see that the location id is also not changing, but there are some records where the localtion ID is changing but still the Trip Distance is 0

-- Lets improve the query and identify which records are faulty
SELECT tpep_pickup_datetime,tpep_dropoff_datetime  FROM new_york_taxi WHERE Trip_distance == 0 AND tpep_pickup_datetime != tpep_dropoff_datetime LIMIT 5;
-- o/p
--  	tpep_pickup_datetime	tpep_dropoff_datetime
-- 1	2017-11-01 00:53:00.0	2017-11-01 00:54:00.0
-- 2	2017-11-01 01:24:00.0	2017-11-01 01:25:00.0
-- 3	2017-11-01 01:22:00.0	2017-11-01 01:23:00.0
-- 4	2017-11-01 01:31:00.0	2017-11-01 01:39:00.0
-- 5	2017-11-01 02:51:00.0	2017-11-01 02:52:00.0
-- It might be possible that the Trip Distance is 0 because someone might have onboard the cab might have cancelled just after at the next min

-- Lets improvise the Query based on PULocationID and DOLocationID , if they are not same then the cab was running and with Payment_type if it is Credit Card, Cash
-- Credit Card in case someone has linked the Credit Card and as a Cancellation Fee and Cash in case Someone onboard the car and thought of cancelling because of some reason
SELECT Payment_type, COUNT(*) as no_of_record FROM new_york_taxi WHERE Trip_distance == 0 AND DOLocationID != PULocationID AND Payment_type IN ( 1, 2 ) GROUP BY Payment_type;
-- o/p
--  	payment_type	no_of_record
-- 1	2	            1315
-- 2	1	            932
-- As we can see the Location is changing and also the charge was deducted via Cash and Card

-- Lets Identify which vendor is at fault
SELECT VendorID, COUNT(*) as no_of_record FROM new_york_taxi 
WHERE Trip_distance == 0 AND DOLocationID != PULocationID AND Payment_type IN ( 1, 2 ) 
GROUP BY VendorID;
-- o/p
--  	vendorid	no_of_record
-- 1	2	1066
-- 2	1	1181
-- As it can be seen that the both the vendors are at equal fault

-- Lets Analyze RateCodeID
SELECT min(RateCodeID) as min_val, max(RateCodeID) as max_val, count(distinct RateCodeID) as count_val
from new_york_taxi;
-- o/p
--  	min_val	max_val	count_val
-- 1	1	99	7
-- As it can be seen that there are 7 distinct value and the maximum is 99 but as the Data Dictionary there are only 6 category and 99 is not a valid category

SELECT RateCodeID, count(*) as no_of_record
FROM new_york_taxi
GROUP BY RateCodeID 
ORDER BY RateCodeID;
-- o/p
--  	ratecodeid	no_of_record
-- 1	1	1142278
-- 2	2	25338
-- 3	3	2562
-- 4	4	586
-- 5	5	3793
-- 6	6	3
-- 7	99	9
-- So we can see 9 records are there which are not valid, so lets analyze by vendor id
SELECT VendorID, count(*) as no_of_record
FROM new_york_taxi
WHERE NOT RateCodeID BETWEEN 1 and 6
GROUP BY VendorID;
-- o/p
--  	vendorid	no_of_record
-- 1	2	1
-- 2	1	8
-- So for Vendor ID 1 most number of records are at fault, so we ignore this data points as they are faulty


-- Lets Analyze Store_and_fwd_flag
SELECT min(Store_and_fwd_flag) as min_val, max(Store_and_fwd_flag) as max_val, count(distinct Store_and_fwd_flag) as count_val
from new_york_taxi;
-- o/p
--  	min_val	max_val	count_val
-- 1	N	Y	2
-- So for this Feature the Data point looks good as there are only two types 

-- Lets analyze the Payment_type
SELECT min(Payment_type) as min_val, max(Payment_type) as max_val, count(distinct Payment_type) as count_val
FROM new_york_taxi;
-- o/p
--  	min_val	max_val	count_val
-- 1	1	4	4
-- As we can see there are only found kinds of Payment Type

-- Lets check out all the types
SELECT Payment_type, count(*) as no_of_record
FROM new_york_taxi
GROUP BY Payment_type
ORDER BY Payment_type;
-- o/p
--  	payment_type	no_of_record
-- 1	1	            790256
-- 2	2	            376374
-- 3	3	            6274
-- 4	4	            1665
-- As we can see there are records with only Payment Type from 1-4, so there is no fault in this Feature

-- Lets Check the Fare_amount
SELECT min(Fare_amount) as min_val, max(Fare_amount) as max_val, count(distinct Fare_amount) as count_val
FROM new_york_taxi;
-- o/p
--  	min_val	max_val	count_val
-- 1	-200	650	    676
-- As we can see the min amount is -200 and 650

-- Lets Try to get the Percentile Values to see the Distribution, 0, 10, 25, 50, 75, 90, 100
SELECT round(perc_val,2) as Percentile_val
FROM (  SELECT explode(percentile_approx( Fare_amount, array(0.05, 0.1, 0.25, 0.75, 0.9, 0.99 ))) as perc_val
        FROM new_york_taxi) temp_table;
-- o/p
--  	percentile_val
-- 1	4.31
-- 2	4.94
-- 3	6.41
-- 4	14.5
-- 5	24.85
-- 6	51.96
-- As we can see above all the percentile value, the Fare_amount range

-- Lets Identify the range of the data
SELECT round(perc_val,2) as Percentile_val
FROM (  SELECT explode(percentile_approx( Fare_amount, array(0.01 , 0.99))) as perc_val
        FROM new_york_taxi ) temp_table;

-- o/p        
--  	percentile_val
-- 1	3.26
-- 2	51.96
-- So Clearly -200 and 650 are outlier

SELECT Fare_amount
FROM new_york_taxi
WHERE NOT Fare_amount between 3 and 52
ORDER BY Fare_amount LIMIT 10;
-- o/p
-- fare_amount
-- -200
-- -175
-- -115.55
-- -90
-- -79
-- -73.11
-- -58.56
-- -52
-- -52

-- So these dat are clearly an outlier, so lets see which Vendor has provided these data and lets increase the limit from 1 to 100
SELECT VendorID, count(*) as no_of_record
FROM new_york_taxi
WHERE round(Fare_amount) < 0 OR ( round(Fare_amount) > 53 AND Trip_distance == 0 ) 
GROUP BY VendorID;
-- o/p
--  	vendorid	no_of_record
-- 1	2	        1130
-- 2	1	        205
-- Here the Vendor ID 2 has most number of fault records
-- Reason for the where Condition, the Fare Amount < 0 usually that is a wrong case
-- And if the Fare is > 53 , there are two possible scenarios
--      a. Sometimes the surcharge is huge or some factors are huge because of which the Fare is high ( travel at night/dawn, events, traffic time )
--      b. But for all of the Trip_Distance can't be Zero, that's a faulty record

-- Lets look for the Field Extra
SELECT min(Extra) as min_val, max(Extra) as max_val, count(distinct Extra) as count_val
FROM new_york_taxi;
-- o/p
--  	min_val	max_val	count_val
-- 1	-10.6	4.8	14

-- Lets check the Value Counts of Different Extra Values
SELECT  Extra, count(*) as no_of_record
FROM new_york_taxi
GROUP BY Extra
ORDER BY Extra;
-- o/p
--  	extra	no_of_record
-- 1	-10.6	1
-- 2	-4.5	5
-- 3	-1	    87
-- 4	-0.5	193
-- 5	0	    631872
-- 6	0.3	    36
-- 7	0.5	    363455
-- 8	0.8	    15
-- 9	1	    174386
-- 10	1.3	    13
-- 11	1.5	    2
-- 12	2	    1
-- 13	4.5	    4502
-- 14	4.8	    1
-- As we can see there are Some Negative Value, As per the Data Dictionaly $0.05 and $0.01 are the rush hour Surcharges and rest all are midnight surcharge
-- a. For -10.6 clearly that seems like a Manual Mistake
-- b. For other negative values there exists some positive values so these also looks like a manual mistake , so only a sign change can be done on these values to rectify the same

-- Lets Check which Vendor Has given most amount of faulty Records
SELECT VendorID, count(*) as no_of_record
FROM new_york_taxi
WHERE Extra < 0
GROUP BY VendorID;
-- o/p
--  	vendorid	no_of_record
-- 1	2	        285
-- 2	1	        1
-- As we can see above for VendorID 2, most number number of Faulty records are present

-- Lets Check for MTA_tax
SELECT min(MTA_tax) as min_val, max(MTA_tax) as max_val, count(distinct MTA_tax) as count_val
from new_york_taxi;
-- o/p
--  	min_val	max_val	count_val
-- 1	-0.5	11.4	5
-- As per the Data Dictionary there is a $0.50 MTA tax that is automatically triggered based on the metered rate in use.

-- Lets check the Value Counts
SELECT MTA_tax, count(*) as no_of_records
FROM new_york_taxi
GROUP BY MTA_tax
ORDER BY MTA_tax;
-- o/p
--  	mta_tax	no_of_records
-- 1	-0.5	544
-- 2	0	    5197
-- 3	0.5	    1168824
-- 4	3	    3
-- 5	11.4	1
-- As we can see above
--  1. Only Two possible Values are possible 0/0.5
--  2. -0.5 seems like a manual mistake for 0.5 ( So sign can be taken care of )
--  3. 3 and 11.4 completely looks illogical here

-- lets identify which Vendor is at fault here
SELECT vendorid, count(*) as no_of_record
FROM new_york_taxi
WHERE MTA_tax NOT IN ( 0 , 0.5)
GROUP BY VendorID;
-- o/p
--  	vendorid	no_of_record
-- 1	2	        547
-- 2	1	        1
-- As we can see for VendorID 2 more number of records are faulty

-- Lets Look for Improvement_surcharge
SELECT min(Improvement_surcharge) as min_val, max(Improvement_surcharge) as max_val, count(distinct Improvement_surcharge) as count_val
from new_york_taxi;
-- o/p
--  	min_val	max_val	count_val
-- 1	-0.3	1	4
-- As per the data dictionary $0.30 improvement surcharge assessed trips at the flag drop, so lets Have Some more look on the data points

-- Value Counts
SELECT Improvement_surcharge,count(*) as no_of_record
FROM new_york_taxi
GROUP BY Improvement_surcharge
ORDER by Improvement_surcharge;
-- o/p
--  	improvement_surcharge	no_of_record
-- 1	-0.3	                558
-- 2	0	                    287
-- 3	0.3	                    1173720
-- 4	1	                    4
-- As it can be seen from above o/p
--      a. 0 and 0.3 are the correct records
--      b. -0.3 seems like a manual mistake in place of 0.3 they have wrongly inserted the data to that needs to be taken care of ( change of Sign )
--      c. But 1 is clearly an error as per the data Dictionary
SELECT vendorid, count(*) as no_of_record
FROM new_york_taxi
WHERE Improvement_surcharge NOT IN ( 0 , 0.3)
GROUP BY VendorID;
-- o/p
--  	vendorid	no_of_record
-- 1	2	562
-- Vendor ID 2 has provided the faulty records in the current case

-- Let check for Tip_amount
SELECT min(Tip_amount) as min_val, max(Tip_amount) as max_val, count(distinct Tip_amount) as count_val
from new_york_taxi;
-- o/p
--  	min_val	max_val	count_val
-- 1	-1.16	450	2133
-- Here the Data Range looks quite Diverse, lets try to get all the percentile values

SELECT round(perc_val,2) as Percentile_val
FROM (  SELECT explode(percentile_approx( Tip_amount, array(0.05, 0.1, 0.25, 0.75, 0.9, 0.99 ))) as perc_val
        FROM new_york_taxi) temp_table;
-- o/p
--  	percentile_val
-- 1	-0.57
-- 2	-0.47
-- 3	-0.2
-- 4	2.45
-- 5	4.24
-- 6	11.71
-- As we can see till 25Percentile we have negative values, but as we know the tip amount can't be negative, putting aside those values lets identify the range

SELECT round(perc_val,2) as Percentile_val
FROM (  SELECT explode(percentile_approx( Tip_amount, array(0.5, 0.75, 0.9, 0.99 ))) as perc_val
        FROM new_york_taxi WHERE Tip_amount >= 0 ) temp_table;
-- o/p
--  	percentile_val
-- 1	1.35
-- 2	2.45
-- 3	4.24
-- 4	11.71
-- As we can see most of the data lie between the range 0 to 12, others are outliers, lets check how many such records are there. Negative values are possible to be a manual mistake

SELECT Tip_amount, count(*) as no_records
FROM new_york_taxi
WHERE Tip_amount NOT BETWEEN 0 and 12  AND Payment_type != 1
GROUP BY Tip_amount
ORDER BY Tip_amount DESC; 
-- o/p
--  	tip_amount	no_records
-- 1	-0.66	1
-- 2	-0.82	1
-- 3	-0.86	1
-- 4	-1.16	1
-- As the Tip Amount Can't be negative and also the Payment Type is from Credit Card only, so these are the faulty record
-- And as a Tip Amount can be as large as possible so there we can't put any restrictions

-- Lets check for which VendorID gave wrong data
SELECT vendorid, count(*) as no_of_record
FROM new_york_taxi
WHERE Tip_amount NOT BETWEEN 0 and 12  AND Payment_type != 1
GROUP BY VendorID;
-- o/p
--  	vendorid	no_of_record
-- 1	2	        4
-- For VendorID 2 more number number of records are faulty

-- lets check for Tolls Amount
SELECT min(Tolls_amount) as min_val, max(Tolls_amount) as max_val, count(distinct Tolls_amount) as count_val
from new_york_taxi;
-- o/p
--   minimum    maximum    unique
-- 1 -5.76    895.89    369
-- There are some Negative Values

SELECT round(perc_val,2) as Percentile_val
FROM (  SELECT explode(percentile_approx( Tolls_amount, array(0.05, 0.1, 0.25, 0.75, 0.9, 0.99 ))) as perc_val
       FROM new_york_taxi) temp_table;
-- o/p
--  	percentile_val
-- 1	-5.46
-- 2	-5.15
-- 3	-4.24
-- 4	-1.2
-- 5	-0.29
-- 6	5.76

-- As it can be seen above that most of the records are below 5.76, lets identify the count
-- As we can see the approximate values are between 

SELECT Tolls_amount, count(*) as no_of_records
FROM new_york_taxi
GROUP BY Tolls_amount
HAVING count(*) > 100 
ORDER BY Tolls_amount DESC;
-- o/p
--  	tolls_amount	no_of_records
-- 1	17.5	        160
-- 2	15.5	        122
-- 3	12.5	        627
-- 4	11.52	        275
-- 5	10.5	        983
-- 6	5.76	        56086
-- 7	5.54	        379
-- 8	2.64	        560
-- 9	0	            1113349

-- As we can see there are large number of data at 5.76 & 0, that's why the percentile approx is coming like this 
-- Lets Try to check the extreme case and the minimum case
-- Minimum case ( If the value is less than 0 )

-- Lets check how many records are there below zero
SELECT `bucket` , count(*) as no_of_record 
FROM ( SELECT CASE
        WHEN Tolls_amount < 0 THEN 1
        WHEN ( Tolls_amount >= 0 and Tolls_amount < 50 ) THEN 2
        WHEN ( Tolls_amount >= 50 and Tolls_amount < 100 ) THEN 3
        WHEN ( Tolls_amount >= 100 and Tolls_amount < 150 ) THEN 4
        WHEN ( Tolls_amount >= 150 and Tolls_amount < 200 ) THEN 5
        else 6 end `bucket`
FROM new_york_taxi ) temp_table
GROUP BY `bucket`
ORDER BY `bucket`;
-- o/p
--  	bucket	no_of_record
-- 1	1	3
-- 2	2	1174544
-- 3	3	18
-- 4	4	2
-- 5	6	2

-- As we can see above what we tried to do is bucket/bin the data in some bracket,
-- so th brackets where if less 0 ==> 1, if between 0 and 50 then ==> 2, if between 50 and 100 then ==> 3, if between 100 and 150 then ==> 4 and if betwen 150 and 200 ==> 5 and rest as 6
-- So we can see above there are very less record which is negative and which are above 150, lets try to have a look on those values


SELECT Tolls_amount, count(*) as number_of_record 
FROM new_york_taxi
WHERE Tolls_amount < 0 or Tolls_amount >= 100
GROUP BY Tolls_amount
ORDER BY Tolls_amount DESC ; 
-- o/p
--  	tolls_amount	number_of_record
-- 1	895.89	        1
-- 2	200	            1
-- 3	125.76	        1
-- 4	101.1	        1
-- 5	-5.76	        3
-- As we can see for the Numbers like 200 and 895.89 looks like a manual mistake because they are extremely high, but for 5.76 this is a sign problem 
-- For 125.76 and 101.1 they doesn't look like a madeup number
-- Lets try to have a look for >100 tolls amount data and understand some key things 

SELECT trip_distance, Tolls_amount  FROM new_york_taxi WHERE Tolls_amount > 100 OR Tolls_amount < 0
ORDER BY Tolls_amount DESC;
-- o/p
--  	trip_distance	tolls_amount
-- 1	9.2	            895.89
-- 2	16.8	        200
-- 3	25.4	        125.76
-- 4	0	            101.1
-- 5	0.22	        -5.76
-- 6	0.05	        -5.76
-- 7	0.03	        -5.76
-- As we can see these are the trip distance and for 895.89, 200, 101.1 looks like a wrong data and for -5.76 this also looks like a sign problem

SELECT vendorid, count(*) as number_of_record 
FROM new_york_taxi
WHERE Tolls_amount < 0 OR Tolls_amount >= 200 OR Tolls_amount ==  101.1
GROUP BY vendorid; 
-- o/p
--  	vendorid	number_of_record
-- 1	2	        3
-- 2	1	        3
-- Both the vendors looks like equally responsible

-- Lets Check for Total_amount       
SELECT min(Total_amount) as min_val, max(Total_amount) as max_val, count(distinct Total_amount) as count_val
from new_york_taxi;
-- o/p
--  	min_val	max_val	count_val
-- 1	-200.8	928.19	6115

-- lets check the price distribution
SELECT round(perc_val,2) as Percentile_val
FROM (  SELECT explode(percentile_approx( Total_amount, array(0.05, 0.1, 0.25, 0.75, 0.9, 0.99 ))) as perc_val
       FROM new_york_taxi) temp_table;
-- o/p
--  	percentile_val
-- 1	5.79
-- 2	6.79
-- 3	8.74
-- 4	17.8
-- 5	30.06
-- 6	70.27

-- This shows the approx percentile distribution, but as we can see the min and max are quite far , i.e the range is quite high, so lets idenitfy what are the anomaly data
-- lets check how many negative records are there

SELECT count(*) as number_of_record
FROM new_york_taxi
WHERE Total_amount < 0;

-- o/p
--  	number_of_record
-- 1	558
-- There are some record which are less than 0 so we need to handle these record, these are wrong data

-- And lets check the outliers on the upper bound
SELECT `bucket` , count(*) as no_of_record 
FROM ( SELECT CASE
        WHEN Total_amount < 0 THEN 1
        WHEN ( Total_amount >= 0 and Tolls_amount < 100 ) THEN 2
        WHEN ( Total_amount >= 100 and Tolls_amount < 200 ) THEN 3
        WHEN ( Total_amount >= 200 and Tolls_amount < 350 ) THEN 4
        WHEN ( Total_amount >= 300 and Tolls_amount < 400 ) THEN 5
        else 6 end `bucket`
FROM new_york_taxi ) temp_table
GROUP BY `bucket`
ORDER BY `bucket`;
-- o/p
--  	bucket	no_of_record
-- 1	1	    558
-- 2	2	    1174007
-- 3	3   	2
-- 4	4	    1
-- 5	6	    1
-- As we can see above there are around 4 data points which has total amount > 200

SELECT vendorid, count(*) as number_of_record 
FROM new_york_taxi
WHERE Total_amount < 0 OR Total_amount > 200
GROUP BY vendorid; 
-- o/p
--  	vendorid	number_of_record
-- 1	2	668
-- 2	1	59

-- As we can see more number Vendor 2 have provided more number of wrong Data

-- 3. You might have encountered unusual or erroneous rows in the dataset. Can you conclude which vendor is doing a bad job in providing 
-- the records using different columns of the dataset? Summarise your conclusions based on every column where these errors are present. 
-- For example,  There are unusual passenger count, i.e. 0 which is unusual.

-- Conclusion
-- a. tpep_pickup_datetime and tpep_pickup_datetime
--      1. Data are provided of year 2003, 2008, 2009
--      2. There was also a record whose dropoff time is in the year 2019
--      3. There are some record where Dropoff Time < Pickup Time Time
--      4. VendorID : 1 has more faulty record

-- b. Passenger_count
--      1. There were some passenger count as 0
--          a. The Driver was not interested to feed in some details regaeding the number of Passenger Onboard
--          b. Or Someone just send some kind off item/parcell
--      2. As most number of records are between passenger count 0-6, but anything above 6 the records are very less. 
--          a. So we can assume that the records entered were wrong, or really in some cars some more numbers of passenger onboard the cab because the cabs are big 
--      3. VendorID 1 has more number of faulty records

-- c. Trip_distance
--      1. In case the Tripdistance was equal to zero, we can see the Location is changing and also the charge was deducted via Cash and Card
--      2. VendorID 1 has more number number of Faulty record

-- d. RateCodeID
--      1.  9 records are there which are not valid for the RateCodeID 99
--      2. Vendor ID 1 most number of records are at fault

-- e. Fare_amount
--      1. Here the Vendor ID 2 has most number of fault records
--      2. Reason for the where Condition, the Fare Amount < 0 usually that is a wrong case
--          And if the Fare is > 53 , there are two possible scenarios
--              a. Sometimes the surcharge is huge or some factors are huge because of which the Fare is high ( travel at night/dawn, events, traffic time )
--              b. But for all of the Trip_Distance can't be Zero, that's a faulty record

--f. Extra
--      1.  There are Some Negative Value, As per the Data Dictionaly $0.05 and $0.01 are the rush hour Surcharges and rest all are midnight surcharge
--          a. For -10.6 clearly that seems like a Manual Mistake
--          b. For other negative values there exists some positive values so these also looks like a manual mistake , so only a sign change can be done on these values to rectify the same
--      2. For VendorID 2, most number number of Faulty records

--g. MTA_tax
--      1. Only Two possible Values are possible 0/0.5
--      2. -0.5 seems like a manual mistake for 0.5 ( So sign can be taken care of )
--      3. 3 and 11.4 completely looks illogical here
--      4. VendorID 2 more number of records are faulty

--h. Improvement_surcharge
--      1. 0 and 0.3 are the correct records
--      2. -0.3 seems like a manual mistake in place of 0.3 they have wrongly inserted the data to that needs to be taken care of ( change of Sign )
--      3. But 1 is clearly an error as per the data Dictionary
--      4. Vendor ID 2 has provided the faulty records

--i. Tip_amount
--      1. As the Tip Amount Can't be negative and also the Payment Type is from Credit Card only, so these are the faulty record
--      2. And as a Tip Amount can be as large as possible so there we can't put any restrictions
--      3. VendorID 2 more number number of records are faulty

--j. Tolls_amount
--      1. This had negative values, which looked liked a sign problem
--      2. There are some trip distance and for 895.89, 200, 101.1 looks like a wrong data, as the trip distance were not so huge for the high Toll Amount
--      3. Both the vendors looks like equally responsible

--h. Total_amount
--      1. Some record which are less than 0
--      2. Some records were extremely high, but there exists only a few data points where total_amount > 200
--      3. Vendor 2 have provided more number of Faulty Data

-- |**********************************************************************************************************************************|
-- Before answering the below questions, you need to create a clean, ORC partitioned table for analysis. Remove all the erroneous rows.
-- |***********************************************************************************************************************************|

DROP TABLE new_york_taxi_partitioned_orc;

-- Then create external table
create external table if not exists new_york_taxi_partitioned_orc
    (VendorID int,
    tpep_pickup_datetime timestamp,
    tpep_dropoff_datetime timestamp,
    Passenger_count int,
    Trip_distance double,
    RateCodeID int,
    Store_and_fwd_flag string,
    PULocationID string,
    DOLocationID string,
    Payment_type int,
    Fare_amount double,
    Extra double,
    MTA_tax double,
    Tip_amount double,
    Tolls_amount double,
    Improvement_surcharge double,
    Total_amount double) partitioned by ( yr int, mnth int)
STORED as orc 
LOCATION '/user/hive/warehouse/sk_jg_case_study'
TBLPROPERTIES ("orc.compress"="SNAPPY");

INSERT OVERWRITE TABLE new_york_taxi_partitioned_orc PARTITION(yr, mnth)
SELECT  *, 
        year(from_unixtime(unix_timestamp( tpep_dropoff_datetime))) as yr,
        month(from_unixtime(unix_timestamp( tpep_dropoff_datetime))) as mnth
FROM new_york_taxi
WHERE NOT ( NOT ( tpep_pickup_datetime BETWEEN '2017-11-01 00:00:00.0' AND '2017-12-31 23:59:59.0' AND 
          tpep_dropoff_datetime BETWEEN '2017-11-01 00:00:00.0' AND '2018-01-01 23:59:59.0' ) OR
          tpep_dropoff_datetime < tpep_pickup_datetime ) AND
      Passenger_count NOT IN ( 0 , 7 , 8 , 9 ) AND
      NOT ( Trip_distance == 0 AND DOLocationID != PULocationID AND Payment_type IN ( 1, 2 ) ) AND
      RateCodeID BETWEEN 1 and 6 AND
      NOT ( round(Fare_amount) < 0 OR ( round(Fare_amount) > 53 AND Trip_distance == 0 ) ) AND
      Extra >= 0 AND
      MTA_tax IN ( 0 , 0.5) AND
      Improvement_surcharge IN ( 0 , 0.3) AND
      NOT ( Tip_amount NOT BETWEEN 0 and 12  AND Payment_type != 1 ) AND
      NOT ( Tolls_amount < 0 OR Tolls_amount >= 200 OR Tolls_amount ==  101.1 ) AND
      NOT ( Total_amount < 0 OR Total_amount > 200 );
      
-- Old Table Record
SELECT count ( *) as old_record FROM new_york_taxi;
-- 1174569

-- New Table Number of record
SELECT count ( *) as new_record FROM new_york_taxi_partitioned_orc;
-- 1164230

SELECT round(((1174569 - 1164230) / 1174569) * 100);
-- 10339 Records were deleted, 1% record were deleted

-- Analysis-I
--1. Compare the overall average fare per trip for November and December.

select  month(from_unixtime(unix_timestamp( tpep_pickup_datetime))) as mnth,
        round(avg(Total_amount),2) as avg_fare 
from new_york_taxi_partitioned_orc
group by month(from_unixtime(unix_timestamp( tpep_pickup_datetime)));

-- o/p
--  	mnth	avg_fare
-- 1	11	    16.38
-- 2	12	    16.08
-- Average Fare for December is less than November

-- 2.Explore the ‘number of passengers per trip’ - 
--   how many trips are made by each level of ‘Passenger_count’? Do most people travel solo or with other people?
select Passenger_count, count(*) as trip_counts 
from new_york_taxi_partitioned_orc
group by Passenger_count
order by trip_counts desc;

-- o/p
--  	passenger_count	trip_counts
-- 1	1	            824990
-- 2	2	            176299
-- 3	5	            54434
-- 4	3	            50558
-- 5	6	            33081
-- 6	4	            24868
-- As we see most of the rides are taken by solo passengers, least by more number od passenger

-- 3. Which is the most preferred mode of payment?
select Payment_type, count(Payment_type) as Counts 
from new_york_taxi_partitioned_orc
group by Payment_type
order by Counts desc;
- o/p
--  	payment_type	counts
-- 1	1	            784186
-- 2	2	            372797
-- 3	3	            5760
-- 4	4	            1487
-- We can see major transaction is done with the payment mode 1 i.e., Credit Card.

-- 4. What is the average tip paid per trip? Compare the average tip with the 
-- 25th, 50th and 75th percentiles and comment whether the ‘average tip’ is a representative statistic (of the central tendency) 
-- of ‘tip amount paid’. Hint: You may use percentile_approx(DOUBLE col, p): 
-- Returns an approximate pth percentile of a numeric column (including floating point types) in the group.

select  round(avg(Tip_amount),2) as average, 
        round(percentile_approx(Tip_amount, 0.25),2) as 25th_percentile,
        round(percentile_approx(Tip_amount, 0.50),2) as 50th_percentile,
        round(percentile_approx(Tip_amount, 0.75),2) as 75th_percentile
from new_york_taxi_partitioned_orc;
-- o/p
--  	average	25th_percentile	50th_percentile	75th_percentile
-- 1	1.85	0	            1.36	        2.45
-- So as we can see the average tip paid per trip is not a representative statistic of ‘tip amount paid’
--  1. As the Value lies between 50th and 75th Percentile

-- 5. Explore the ‘Extra’ (charge) variable - what fraction of total trips have an extra charge is levied?

with ft as (
            select VendorID,
                case when Extra > 0 then Extra end as charged,
                case when Extra = 0 then Extra end as not_charged
            from new_york_taxi_partitioned_orc)

select  count(charged) as charged, 
        count(not_charged) not_charged, 
        round(count(charged)*100/(count(charged) + count(not_charged)),2) as fraction
from ft;
-- o/p
--  	charged	not_charged	fraction
-- 1	538767	625463	    46.28
-- So as we can see above around 46.28% of total trips have an extra charge levied

-- Analysis-II

-- What is the correlation between the number of passengers on any given trip, and the tip paid per trip? 
-- Do multiple travellers tip more compared to solo travellers? Hint: Use CORR(Col_1, Col_2)

SELECT round( corr(Passenger_count,tip_amount),5)  as correlation
FROM new_york_taxi_partitioned_orc;
-- o/p
--  	correlation
-- 1	-0.00463

-- As it can be seen that the correleation value is negative and very small, so there is so strong correlation between PassengerCount and TipAmount

SELECT round(corr( single_pas, tip_amount ),5) as correlation
       FROM ( SELECT CASE WHEN Passenger_count == 1 then 1
                          ELSE 0 END as single_pas , tip_amount
              FROM new_york_taxi_partitioned_orc
            ) temp_table;
-- o/p
--  	correlation
-- 1	0.00496
-- There is a very low positive correlation between single vs mutlple passenger count ( tip amount )

SELECT single_pas as passenger_type, round(avg(tip_amount ),2) as average
       FROM ( SELECT CASE WHEN Passenger_count == 1 then 'Solo'
                          ELSE 'Multiple' END as single_pas , tip_amount
              FROM new_york_taxi_partitioned_orc
            ) temp_table
        GROUP BY single_pas;
        
-- o/p
--  	passenger_type	average
-- 1	Multiple	    1.83
-- 2	Solo	        1.86
-- As we can see Multiple Passenger traveller tip less compared to Single Passenger

--2. Segregate the data into five segments of ‘tip paid’: [0-5), [5-10), [10-15) , [15-20) and >=20. Calculate the percentage share of each bucket (i.e. the fraction of trips falling in each bucket).

SELECT range_of_tip, round((count(*)*100/1164230),2) as percentage
FROM 
( SELECT 
    CASE when ( tip_amount >= 0 and tip_amount < 5 ) then   '[0-5)'
         when ( tip_amount >= 5 and tip_amount < 10 ) then  '[5-10)'
         when ( tip_amount >= 10 and tip_amount < 15 ) then  '[10-15)'
         when ( tip_amount >= 15 and tip_amount < 20 ) then  '[15-20)'
         when ( tip_amount >= 20 ) then '>=20' END range_of_tip
    FROM new_york_taxi_partitioned_orc) temp_table
GROUP BY range_of_tip
ORDER BY percentage DESC;
-- o/p
--  	range_of_tip	percentage
-- 1	[0-5)	        92.15
-- 2	[5-10)	        5.65
-- 3	[10-15)	        1.87
-- 4	[15-20)	        0.23
-- 5	>=20	        0.09
-- Highest Number of tip happened in the group [0-5) around 92% and least tip happened in the grp >=20 ~1%

-- 3. Which month has a greater average ‘speed’ - November or December? Note that the variable ‘speed’ will have to be derived from other metrics. Hint: You have columns for distance and time.
SELECT mnth , 
    round(avg(Trip_distance/((unix_timestamp(tpep_dropoff_datetime)-unix_timestamp(tpep_pickup_datetime) )/3600) ),3) average_speed
FROM new_york_taxi_partitioned_orc
GROUP BY mnth
ORDER BY average_speed DESC;
-- o/p
--  	mnth	average_speed
-- 1	12	    11.074
-- 2	11	    10.987
-- 3	1	    9.853
-- As we can see the December has the highest average Speed as compared to other months

-- 4.Analyse the average speed of the most happening days of the year, i.e. 31st December (New year’s eve) and 25th December (Christmas) and compare it with the overall average.

-- Lets Check the Average speed on Christmae, Newyear and other days
with ft as
(   select trip_distance,   tpep_dropoff_datetime,  tpep_pickup_datetime,
        case    when ((tpep_pickup_datetime>='2017-12-25 00:00:00.0' and tpep_pickup_datetime<'2017-12-26 00:00:00.0')) then 'christmas'
                when ((tpep_pickup_datetime>='2017-12-31 00:00:00.0' and tpep_pickup_datetime<'2018-01-01 00:00:00.0')) then 'new_years' else 'regular_days' end as DayType
        from new_york_taxi_partitioned_orc
)
select DayType, round(avg(trip_distance/((unix_timestamp(tpep_dropoff_datetime) - unix_timestamp(tpep_pickup_datetime))/3600)),2) as average_speed
from ft
group by DayType;
-- o/p
--  	daytype	        average_speed
-- 1	christmas	    15.24
-- 2	new_years	    13.22
-- 3	regular_days	10.97

-- As we can see the Average Speed on Chistmas is higher than other three days

-- Now lets gets the overall average speed
select round(avg(trip_distance/((unix_timestamp(tpep_dropoff_datetime)-unix_timestamp(tpep_pickup_datetime) )/3600) ),3) average_speed
from new_york_taxi_partitioned_orc;
-- o/p
--  	average_speed
-- 1	11.031
-- As we can see above on the Holiday's specially on NewYear /Christmas, the speed is higher as compared to average speed, As the possible reason is the streets are more empty than normal days